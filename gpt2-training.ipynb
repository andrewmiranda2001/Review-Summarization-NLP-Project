{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7085917,"sourceType":"datasetVersion","datasetId":4082630},{"sourceId":153347083,"sourceType":"kernelVersion"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:31:03.002509Z","iopub.execute_input":"2023-12-03T20:31:03.002943Z","iopub.status.idle":"2023-12-03T20:31:12.940358Z","shell.execute_reply.started":"2023-12-03T20:31:03.002914Z","shell.execute_reply":"2023-12-03T20:31:12.938784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, random_split\nfrom transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n\n# Set a random seed for reproducibility\ntorch.manual_seed(42)\n\n# Load the tokenizer with the same settings as during initial training\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium', bos_token='', eos_token='', pad_token='')\n\n# Load your dataset with reviews and summaries\ndf = pd.read_csv('/kaggle/input/cleaned-amazon-reviews/your_file.csv')\ndescriptions = df['Text']\nsummaries = df['Summary']\n\n# Define a special token for separating review and summary\nsep_token = '<|summary|>'\ntokenizer.add_special_tokens({'additional_special_tokens': [sep_token]})","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:32:19.803169Z","iopub.execute_input":"2023-12-03T20:32:19.803580Z","iopub.status.idle":"2023-12-03T20:32:46.044216Z","shell.execute_reply.started":"2023-12-03T20:32:19.803535Z","shell.execute_reply":"2023-12-03T20:32:46.043293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define your dataset class for review-summary pairs\nclass ReviewSummaryDataset(Dataset):\n    def __init__(self, reviews, summaries, tokenizer, max_length):\n        self.input_ids = []\n        self.attn_masks = []\n        self.labels = []\n        for review, summary in zip(reviews, summaries):\n            combined_text = review + ' ' + sep_token + ' ' + summary\n            encodings_dict = tokenizer(combined_text, truncation=True, max_length=max_length, padding=\"max_length\")\n            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n            self.labels.append(torch.tensor(encodings_dict['input_ids']))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attn_masks[idx], self.labels[idx]\n\n# Create the dataset\nmax_length = 1024  # Adjust as needed\ndataset = ReviewSummaryDataset(descriptions, summaries, tokenizer, max_length=max_length)\ntrain_size = int(0.9 * len(dataset))\ntrain_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n\nmodel_save_path = \"/kaggle/input/gpt2-pt3/results/checkpoint-5000\"\n# Load the model from the saved checkpoint\nmodel = GPT2LMHeadModel.from_pretrained(model_save_path)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:32:56.638951Z","iopub.execute_input":"2023-12-03T20:32:56.640025Z","iopub.status.idle":"2023-12-03T20:34:16.374897Z","shell.execute_reply.started":"2023-12-03T20:32:56.639990Z","shell.execute_reply":"2023-12-03T20:34:16.373600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results', \n    num_train_epochs=3,  # Adjust number of epochs as needed\n    logging_steps=100, \n    save_steps=5000,\n    per_device_train_batch_size=1, \n    per_device_eval_batch_size=1,\n    warmup_steps=10, \n    weight_decay=0.05, \n    logging_dir='./logs', \n    report_to='none'\n)\n\n# Define your data collator function\ndef my_data_collator(data):\n    input_ids = torch.stack([item[0] for item in data])\n    attention_mask = torch.stack([item[1] for item in data])\n    labels = torch.stack([item[2] for item in data])\n    return {\n        'input_ids': input_ids, \n        'attention_mask': attention_mask, \n        'labels': labels\n    }\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model, \n    args=training_args, \n    train_dataset=train_dataset, \n    eval_dataset=val_dataset, \n    data_collator=my_data_collator\n)\n\n# Start fine-tuning\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:30:17.806845Z","iopub.execute_input":"2023-12-03T20:30:17.807128Z","iopub.status.idle":"2023-12-03T20:30:18.070653Z","shell.execute_reply.started":"2023-12-03T20:30:17.807104Z","shell.execute_reply":"2023-12-03T20:30:18.069057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model and tokenizer\nmodel_save_path = \"/kaggle/working/finetuned-gpt2-summary\"\nmodel.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T20:30:17.806845Z","iopub.execute_input":"2023-12-03T20:30:17.807128Z","iopub.status.idle":"2023-12-03T20:30:18.070653Z","shell.execute_reply.started":"2023-12-03T20:30:17.807104Z","shell.execute_reply":"2023-12-03T20:30:18.069057Z"},"trusted":true},"execution_count":null,"outputs":[]}]}