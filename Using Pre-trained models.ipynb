{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7068452,"sourceType":"datasetVersion","datasetId":4070360},{"sourceId":7069078,"sourceType":"datasetVersion","datasetId":4070725},{"sourceId":7069225,"sourceType":"datasetVersion","datasetId":4070808},{"sourceId":7069242,"sourceType":"datasetVersion","datasetId":4070835}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\ndata = pd.read_csv(\"/kaggle/input/cleaned-amazon-reviews/your_file.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:45:42.687673Z","iopub.execute_input":"2023-11-27T21:45:42.688021Z","iopub.status.idle":"2023-11-27T21:45:52.033148Z","shell.execute_reply.started":"2023-11-27T21:45:42.687990Z","shell.execute_reply":"2023-11-27T21:45:52.031869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import T5Tokenizer, TFT5ForConditionalGeneration\nmodel_name = 't5-large'\nt5_model = TFT5ForConditionalGeneration.from_pretrained(model_name)\nt5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n\ndef summarize_t5(text, model, tokenizer, max_length=100, num_beams=5):\n    # T5 uses a prefix like \"summarize: \"\n    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n    summary_ids = model.generate(inputs['input_ids'], max_length=max_length, num_beams=num_beams, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import PegasusForConditionalGeneration, PegasusTokenizer\nmodel_name='google/pegasus-xsum'\np_tokenizer = PegasusTokenizer.from_pretrained(model_name)\np_model = PegasusForConditionalGeneration.from_pretrained(model_name)\n\ndef summarize_pegasus(text, model, tokenizer, max_length=100, num_beams=5):\n    # PEGASUS doesn't need a specific prefix\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n    summary_ids = model.generate(inputs['input_ids'], max_length=max_length, num_beams=num_beams, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration\nmodel_name='facebook/bart-large-cnn'\nb_tokenizer = BartTokenizer.from_pretrained(model_name)\nb_model = BartForConditionalGeneration.from_pretrained(model_name)\n\ndef summarize_bart(text, model, tokenizer, max_length=100, num_beams=5):\n    # BART doesn't need a specific prefix\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    summary_ids = model.generate(inputs['input_ids'], max_length=max_length, num_beams=num_beams, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nimport sys\n\n# Add the directory containing attention.py to the Python path\nsys.path.append('/kaggle/input/attention-layer')\n\n# Now import the AttentionLayer\nfrom attention import AttentionLayer\n\n# Load the trained seq2seq model\nmodel_path = '/kaggle/input/seq2seq-model/summary.h5'\nmodel = load_model(model_path, custom_objects={'AttentionLayer': AttentionLayer})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    review = data['Text'][i]\n    p_review = data['cleaned_text'][i]\n    dataset_summ = data['Summary'][i]\n    \n    t5_summary = summarize_t5(review, t5_model, t5_tokenizer)\n    p_summary = summarize_pegasus(review, p_model, p_tokenizer)\n    b_summary = summarize_bart(review, b_model, b_tokenizer)\n    \n    p_t5_summary = summarize_t5(p_review, t5_model, t5_tokenizer)\n    p_p_summary = summarize_pegasus(p_review, p_model, p_tokenizer)\n    p_b_summary = summarize_bart(p_review, b_model, b_tokenizer)\n\n    # Original Review\n    print(\"Review:\")\n    print(review)\n    print()\n\n    # Dataset's Summary\n    print(\"Dataset's summary:\")\n    print(dataset_summ)\n    print()\n\n    # T5 Summary\n    print(\"T5 summary:\")\n    print(t5_summary)\n    print(\"T5 summary (preprocessed):\")\n    print(p_t5_summary)\n    print()\n\n    # PEGASUS Summary\n    print(\"PEGASUS summary:\")\n    print(p_summary)\n    print(\"PEGASUS summary (preprocessed):\")\n    print(p_p_summary)\n    print()\n\n    # BART Summary\n    print(\"BART summary:\")\n    print(b_summary)\n    print(\"BART summary (preprocessed):\")\n    print(p_b_summary)\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T21:47:04.228718Z","iopub.execute_input":"2023-11-27T21:47:04.229773Z","iopub.status.idle":"2023-11-27T21:47:04.505952Z","shell.execute_reply.started":"2023-11-27T21:47:04.229741Z","shell.execute_reply":"2023-11-27T21:47:04.504665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# THIS BLOCK CONCATS ALL TEN REVIEWS AND THEN SUMMARIZES\n\nimport pandas as pd\n\n# Load the CSV file\nfile_path = '/kaggle/input/yelp-reviews/5_business_10_review.csv'\ndata = pd.read_csv(file_path)\n\n# Process the data\nfor business_name in data['Business Name'].unique():\n    business_reviews = data[data['Business Name'] == business_name]['Reviews']\n    concatenated_reviews = \" \".join(business_reviews)\n\n    # Generate summaries\n    t5_summary = summarize_t5(concatenated_reviews, t5_model, t5_tokenizer)\n    pegasus_summary = summarize_pegasus(concatenated_reviews, p_model, p_tokenizer)\n    bart_summary = summarize_bart(concatenated_reviews, b_model, b_tokenizer)\n\n    # Print the results\n    print(f\"Reviews: \")\n    print(concatenated_reviews)\n    print(f\"Business: {business_name}\")\n    print(\"T5 Summary:\", t5_summary)\n    print(\"PEGASUS Summary:\", pegasus_summary)\n    print(\"BART Summary:\", bart_summary)\n    print(\"\\n---\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# THIS BLOCK SUMMARIZES EACH REVIEW, CONCATS THE 10 SUMMARIES, \n# AND THEN SUMMARIZES THE SUMMARIES INTO ONE\n\nfor business_name in data['Business Name'].unique():\n    business_reviews = data[data['Business Name'] == business_name]['Reviews']\n\n    # Print all reviews for the business\n    print(f\"Business: {business_name}\\nAll Reviews:\")\n    for review in business_reviews:\n        print(review)\n\n    # Individual summaries for each model\n    print(\"\\n--- Individual Summaries (T5) ---\")\n    t5_summaries = [summarize_t5(review, t5_model, t5_tokenizer) for review in business_reviews]\n    for summary in t5_summaries:\n        print(summary)\n\n    print(\"\\n--- Individual Summaries (PEGASUS) ---\")\n    pegasus_summaries = [summarize_pegasus(review, p_model, p_tokenizer) for review in business_reviews]\n    for summary in pegasus_summaries:\n        print(summary)\n\n    print(\"\\n--- Individual Summaries (BART) ---\")\n    bart_summaries = [summarize_bart(review, b_model, b_tokenizer) for review in business_reviews]\n    for summary in bart_summaries:\n        print(summary)\n\n    # Concatenate and summarize the individual summaries for each model\n    print(\"\\n--- Final Summaries ---\")\n    print(\"T5 Final Summary:\", summarize_t5(\" \".join(t5_summaries), t5_model, t5_tokenizer))\n    print(\"PEGASUS Final Summary:\", summarize_pegasus(\" \".join(pegasus_summaries), p_model, p_tokenizer))\n    print(\"BART Final Summary:\", summarize_bart(\" \".join(bart_summaries), b_model, b_tokenizer))\n    print(\"\\n=============================\\n\")","metadata":{},"execution_count":null,"outputs":[]}]}