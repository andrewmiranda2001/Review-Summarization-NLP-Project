{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7052770,"sourceType":"datasetVersion","datasetId":4059198}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***This file attempts at turning some of our seq2seq model summaries into natural language since we are getting very short two word summaries***","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-29T22:20:45.650744Z","iopub.execute_input":"2023-11-29T22:20:45.651169Z","iopub.status.idle":"2023-11-29T22:20:58.198010Z","shell.execute_reply.started":"2023-11-29T22:20:45.651138Z","shell.execute_reply":"2023-11-29T22:20:58.196998Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ***Using GPT-2 with prompt***","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n# Load pre-trained model and tokenizer\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\n# Set the pad token to the EOS token\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = 'left'\n\npredicted_summaries = [\n    \"dog loves\", \"love\", \"great product\", \"great deal\", \"vegetarian\"\n]\n\nexpanded_summaries = []\n\nfor summary in predicted_summaries:\n    prompt = f\"Turn this product review into a complete sentence: {summary}\"\n    inputs = tokenizer.encode_plus(prompt, return_tensors='pt', padding='max_length', truncation=True, max_length=50)\n    \n    # Generate a response to the prompt\n    outputs = model.generate(**inputs, max_length=60, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    expanded_summaries.append(generated_text)\n    print(\"Prompt: \", prompt)\n    print(\"Generated Text: \\n\", generated_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T22:20:58.200172Z","iopub.execute_input":"2023-11-29T22:20:58.200535Z","iopub.status.idle":"2023-11-29T22:21:22.571298Z","shell.execute_reply.started":"2023-11-29T22:20:58.200502Z","shell.execute_reply":"2023-11-29T22:21:22.570494Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ea29a2092b4f2ebb4be8c34b021cd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f1c4fd4686e448ca2dabd2ce296b086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f5c7706914d464c9fa5cac49b23e6c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aee9c43cb5c4c58a40ce2d771ec53e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f40484119f2420cbf5dc607bd6ea2d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"097e453a377940aa83c654ed68b7a3ae"}},"metadata":{}},{"name":"stdout","text":"Prompt:  Turn this product review into a complete sentence: dog loves\nGenerated Text: \n Turn this product review into a complete sentence: dog loves to play with toys.\n\nThe dog loves\nPrompt:  Turn this product review into a complete sentence: love\nGenerated Text: \n Turn this product review into a complete sentence: love it.\n\nI've been using this product\nPrompt:  Turn this product review into a complete sentence: great product\nGenerated Text: \n Turn this product review into a complete sentence: great product.\n\nI've been using this product for\nPrompt:  Turn this product review into a complete sentence: great deal\nGenerated Text: \n Turn this product review into a complete sentence: great deal.\n\nI've been using this product for\nPrompt:  Turn this product review into a complete sentence: vegetarian\nGenerated Text: \n Turn this product review into a complete sentence: vegetarianism is a bad idea.\n\nI'm\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ***Attempt at using a rule-based POS tagger for sentence generation***","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nnltk.download('averaged_perceptron_tagger')\n\ndef complete_sentence(phrase):\n    words = word_tokenize(phrase)\n    pos_tags = nltk.pos_tag(words)\n    \n    if len(words) == 1:\n        if pos_tags[0][1] in ['NN', 'NNP']:\n            return f\"This product is called {words[0]}.\"\n        elif pos_tags[0][1] == 'JJ':\n            return f\"This product is {words[0]}.\"\n    \n    elif len(words) == 2:\n        if pos_tags[0][1] in ['NN', 'NNP'] and pos_tags[1][1] == 'VB':\n            return f\"Customers love the {words[0]}.\"\n        elif pos_tags[0][1] == 'JJ' and pos_tags[1][1] in ['NN', 'NNP']:\n            return f\"This is a {phrase}.\"\n        elif pos_tags[0][1] in ['NN', 'NNP'] and pos_tags[1][1] == 'JJ':\n            return f\"This {words[0]} is {words[1]}.\"\n        elif 'deal' in words:\n            return f\"This product offers a {phrase}.\"\n    \n    # Special cases based on meaning\n    if 'value' in words or 'delicious' in words:\n        return f\"Customers report this product is {phrase}.\"\n    if words[-1] == 'product':\n        return f\"This is a {phrase}.\"\n\n    # If none of the above rules apply, fall back to a default phrasing\n    return f\"This product is {phrase}.\"\n\n\n\nexpanded_summaries = [complete_sentence(summary) for summary in predicted_summaries]\n\nprint(expanded_summaries)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T22:21:22.572900Z","iopub.execute_input":"2023-11-29T22:21:22.573731Z","iopub.status.idle":"2023-11-29T22:21:23.981566Z","shell.execute_reply.started":"2023-11-29T22:21:22.573690Z","shell.execute_reply":"2023-11-29T22:21:23.980473Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n['This product is dog loves.', 'This product is called love.', 'This is a great product.', 'This is a great deal.', 'This product is vegetarian.']\n","output_type":"stream"}]}]}