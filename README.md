# Review-Summarization-NLP-Project

So far, preprocessed the Amazon Fine Food Reviews dataset and trained a Seq2Seq model. Then I worked on fine tuning the model to produce more optimal summaries for our use case and then experimented with textrank and kmeans clustering with BERT/GPT2 embeddings. I also trained a Text-to-Text transformer using our data, then evaluated pretrained models (BART, T5, and PEGASUS) on summarizing lists of summaries. I then attempted to convert these outputs into 1-2 humanlike sentences by either prompting GPT-2 or using a rule-based POS tagger.
